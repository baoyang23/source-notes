## 								个人工作履历



####  在校期间

​	TODO



####  ICIL (2019-07 ~ 至今) ,  国际物流/仓储 ,  深圳

####    Label-Service + Airflow

​	 	这里使用airflow(pyton)的原因,方便快速与第三方进行对接和内部一些定时任务(主要是生成execl和报表数据).   label-service是单独的一个微服务,也是内存的,目的在于是提供内部的common接口,需要与第三方打印label等接口,都在这个服务中实现。这样就避免了,内部其他服务如果需要与第三方对接的话,就需要在写一套的问题。

​         **这里的亮点个人觉得,使用axon框架来记录与第三方进行对接的情况,根据event来查询每次的情况一目了然,这样与第三方进行汇总(费用计算)的时候,是非常清晰的.对于后期需要生成的报表也是非常的好的. **  Airflow这里的作用就是,通过python脚本的特性,快速,接入第三方的数据,很快。比如我们从第三方平台(shopify)等这种,接过来orders信息,然后丢给内部存库系统,就可以很快速的实现.

​        总结 :  对Apollo配置中心,Eureka,Feign,Kafka,Airflow等使用熟练,并且项目中遇见的问题,加强了对框架内部执行原理的理解。



####   同步服务

​	  这个服务就有三个微服务组成的一个大的基础服务. Sync / Number / Milestone.

​      我这边主要是负责 Sync服务,但是由于一直员工辞职的原因,导致我对Number/Milestone也是有一定的了解,毕竟修改过里面的代码. Sync1.0主要是与canal1.1直接相互,来读取数据库来进行数据同步(这里肯定是二边的表是完全不一样的,不然就话,就会直接使用canal开发的来通过,或者通过mysql主从来同步,正是因为不能,所以就有了这个服务).  Sync2.0,我负责的, canal1.0升级到1.3,同时sync不直接与canal交互,加入kafka来加交互. 

------



####  FPI(实习2018-11  ~  2019-05) , 环保业务 , 武汉

​		在FPI最初的时候,想起来好像做到的最多的东西就是分析数据。虽然后面对基础服务的拆分,我这边也就拆了二个服务模块出来,然后负责新开发一个。

​		

##### 	 大气网格基础服务(All in one)

​	 技术点 :  SpringBoot1.x + JDBC Template  MongoDB  Kafka Flyway  (这里关于操作DB的都封装成一个类,注入到Spring容器中,只需要注入这个封装的类,来调用方法即可)

​	dev : gitlab + gitlab(CI/CD) + gitlab runner .(项目管理也是使用gitlab)		

​	功能(我负责) : 最初的一版就是直接基于这个项目来些的,前端需要提供的所有的接口都是基于项目来提供(前后端分离,还是移动端)。 我就负责开发几个报告的接口.  **根据输入的天到MongoDB里面查询每个站点的每天的信息(六因子)** 。 **根据站点名称(这里的站点是有层级关系的.),天范围,来查询六因子,AQI等信息,并且同时进行同比/环比等分析。**   **根据天范围(周/月)等从MongoDB中查询出值,根据需求提供的,比如AQI > 250 就是严重污染等,行分析(这里是提供分析接口给前端UI,使用echarts来做图形)。** 后面的拆分都是基于这个服务,来将里面的功能拆分出来.



####  拆分微服务

​    对大气网格基础服务进行拆分, 根据对应的模块来拆分成不同的微服务应用. **个人认为这样的好处,就是对每个模块进行最大的复用,并且都有对应的人员负责,理解起单独的业务更快.还是一点最主要的是，我们这个系统可以给城市A使用,不需要修改什么,按照模块(这里拆出来的模块),根据需求的需要,也可以在城市B使用,这个就需要看每个城市具体的需要了.**     签到微服务(sign-service), 这里我还单独负责一个签到的微服务开发,主要是根据网格员的打卡的位置,和配置的对应获取点位信息(经纬度),类似于每天上下班打卡,最后出周/月/时间段 的报表统计API. 然后根据每个网格员的点位信息,传递给前端用来地图展示。根据一段时间的经纬度来判断网格员是否有偷懒的问题. 这里主要的难点, 每个网格员每天的点位信息怎么存储 ?  每五分中一条,难道来一条就insert 一条 ？那这样得存储多少条啊？ 这里是使用 json 字段来存储点位信息,然后预留三个字段,经纬度,时间即可.